#!/usr/bin/env python3
"""
Unix Timestamp Migration Script for Claude Vector Database

Adds timestamp_unix fields to existing conversations for fast ChromaDB filtering.
Includes safety features: backup, rollback, dry-run, and progress monitoring.

Usage:
    python migrate_timestamps.py --dry-run          # Safe preview
    python migrate_timestamps.py --backup           # Full migration with backup
    python migrate_timestamps.py --rollback         # Restore from backup
"""

import sys
import json
import time
import shutil
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

# Add vector DB modules
sys.path.append('/home/user/.claude-vector-db')

try:
    from database.vector_database import ClaudeVectorDatabase
    from database.conversation_extractor import ConversationExtractor
except ImportError as e:
    print(f"‚ùå Error importing vector DB modules: {e}")
    print("Make sure you're running from /home/user/.claude-vector-db/")
    sys.exit(1)


class TimestampMigrator:
    """Handles safe migration of string timestamps to Unix timestamps"""
    
    def __init__(self, batch_size: int = 1000, backup: bool = True):
        self.batch_size = batch_size
        self.backup = backup
        self.backup_dir = Path('./migration_backup')
        self.log_file = Path("/home/user/.claude-vector-db-enhanced/system/migration.log")
        
        # Initialize database
        try:
            self.db = ClaudeVectorDatabase()
            print("‚úÖ Connected to ChromaDB")
        except Exception as e:
            print(f"‚ùå Failed to connect to ChromaDB: {e}")
            sys.exit(1)
    
    def log(self, message: str, level: str = "INFO"):
        """Log message to file and console"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_entry = f"[{timestamp}] {level}: {message}"
        
        print(log_entry)
        
        # Append to log file
        with open(self.log_file, 'a') as f:
            f.write(log_entry + '\n')
    
    def create_backup(self) -> bool:
        """Create backup of ChromaDB before migration"""
        if not self.backup:
            self.log("Skipping backup (--no-backup flag)")
            return True
            
        try:
            self.backup_dir.mkdir(exist_ok=True)
            
            # Backup ChromaDB directory
            chroma_backup = self.backup_dir / 'chroma_db'
            if chroma_backup.exists():
                shutil.rmtree(chroma_backup)
            
            shutil.copytree('./chroma_db', chroma_backup)
            
            # Save migration metadata
            backup_info = {
                'timestamp': datetime.now().isoformat(),
                'original_chroma_size': self.get_directory_size('./chroma_db'),
                'conversation_count': self.get_conversation_count()
            }
            
            with open(self.backup_dir / 'migration_info.json', 'w') as f:
                json.dump(backup_info, f, indent=2)
            
            self.log(f"‚úÖ Backup created: {chroma_backup}")
            return True
            
        except Exception as e:
            self.log(f"‚ùå Backup failed: {e}", "ERROR")
            return False
    
    def rollback(self) -> bool:
        """Restore from backup"""
        try:
            chroma_backup = self.backup_dir / 'chroma_db'
            if not chroma_backup.exists():
                self.log("‚ùå No backup found for rollback", "ERROR")
                return False
            
            # Remove current database
            if Path('./chroma_db').exists():
                shutil.rmtree('./chroma_db')
            
            # Restore from backup
            shutil.copytree(chroma_backup, './chroma_db')
            
            self.log("‚úÖ Rollback completed successfully")
            return True
            
        except Exception as e:
            self.log(f"‚ùå Rollback failed: {e}", "ERROR")
            return False
    
    def get_directory_size(self, path: str) -> int:
        """Get directory size in bytes"""
        total = 0
        for file_path in Path(path).rglob('*'):
            if file_path.is_file():
                total += file_path.stat().st_size
        return total
    
    def get_conversation_count(self) -> int:
        """Get total conversation count"""
        try:
            return self.db.collection.count()
        except Exception as e:
            self.log(f"‚ö†Ô∏è Failed to get conversation count: {e}", "WARN")
            return 0
    
    def convert_timestamp_to_unix(self, timestamp_str: str) -> Optional[float]:
        """Convert ISO timestamp string to Unix timestamp"""
        try:
            # Handle Z suffix (UTC timezone)
            if timestamp_str.endswith('Z'):
                timestamp_str = timestamp_str[:-1] + '+00:00'
            
            dt = datetime.fromisoformat(timestamp_str)
            return dt.timestamp()
            
        except Exception as e:
            self.log(f"‚ö†Ô∏è Failed to convert timestamp '{timestamp_str}': {e}", "WARN")
            return None
    
    def dry_run(self) -> Dict[str, Any]:
        """Preview migration without making changes"""
        self.log("üîç Starting dry run migration preview...")
        
        # Get sample of conversations
        try:
            sample_results = self.db.search_conversations(query="test", n_results=10)
            
            preview_stats = {
                'total_conversations': len(sample_results),
                'sample_conversions': [],
                'conversion_errors': 0,
                'estimated_time_seconds': 0
            }
            
            # Test timestamp conversion on sample
            start_time = time.time()
            
            for result in sample_results:
                timestamp_str = result.get('timestamp', '')
                if timestamp_str:
                    unix_ts = self.convert_timestamp_to_unix(timestamp_str)
                    
                    conversion_info = {
                        'original': timestamp_str,
                        'unix': unix_ts,
                        'success': unix_ts is not None
                    }
                    
                    if unix_ts is None:
                        preview_stats['conversion_errors'] += 1
                    
                    preview_stats['sample_conversions'].append(conversion_info)
            
            # Estimate timing
            sample_time = time.time() - start_time
            if len(sample_results) > 0:
                time_per_record = sample_time / len(sample_results)
                total_records = self.get_conversation_count()
                preview_stats['estimated_time_seconds'] = int(time_per_record * total_records)
            
            # Print preview
            self.log("üìã Dry Run Results:")
            self.log(f"  Total conversations to migrate: {total_records}")
            self.log(f"  Sample conversions tested: {len(sample_results)}")
            self.log(f"  Conversion errors: {preview_stats['conversion_errors']}")
            self.log(f"  Estimated migration time: {preview_stats['estimated_time_seconds']} seconds")
            
            if preview_stats['conversion_errors'] > 0:
                self.log("‚ö†Ô∏è Some timestamp conversions failed - check log for details", "WARN")
            
            # Show sample conversions
            self.log("üìù Sample timestamp conversions:")
            for i, conv in enumerate(preview_stats['sample_conversions'][:3], 1):
                status = "‚úÖ" if conv['success'] else "‚ùå"
                self.log(f"  {i}. {status} {conv['original']} -> {conv['unix']}")
            
            return preview_stats
            
        except Exception as e:
            self.log(f"‚ùå Dry run failed: {e}", "ERROR")
            return {}
    
    def migrate(self) -> bool:
        """Perform full migration with Unix timestamp addition"""
        self.log("üöÄ Starting Unix timestamp migration...")
        
        # Create backup first
        if not self.create_backup():
            self.log("‚ùå Migration aborted - backup failed", "ERROR")
            return False
        
        try:
            # Get all conversations directly from ChromaDB
            self.log("üìä Accessing ChromaDB collection directly...")
            
            total_conversations = self.db.collection.count()
            self.log(f"üìà Found {total_conversations} conversations to migrate")
            
            # Get all conversation data in batches using ChromaDB's get() method
            migrated_count = 0
            error_count = 0
            batch_start_time = time.time()
            
            # Process all conversations in batches
            batch_size = self.batch_size
            
            for offset in range(0, total_conversations, batch_size):
                try:
                    # Get batch of conversations with metadata
                    batch_result = self.db.collection.get(
                        limit=batch_size,
                        offset=offset,
                        include=['metadatas', 'documents']
                    )
                    
                    batch_ids = batch_result['ids']
                    batch_metadatas = batch_result['metadatas']
                    batch_documents = batch_result['documents']
                    
                    # Prepare updated metadata for batch
                    updated_metadatas = []
                    updated_ids = []
                    
                    for i, (conv_id, metadata, document) in enumerate(zip(batch_ids, batch_metadatas, batch_documents)):
                        if metadata and 'timestamp' in metadata:
                            timestamp_str = metadata['timestamp']
                            unix_ts = self.convert_timestamp_to_unix(timestamp_str)
                            
                            if unix_ts is not None:
                                # Add timestamp_unix to existing metadata
                                updated_metadata = metadata.copy()
                                updated_metadata['timestamp_unix'] = unix_ts
                                
                                updated_metadatas.append(updated_metadata)
                                updated_ids.append(conv_id)
                                migrated_count += 1
                            else:
                                error_count += 1
                                self.log(f"‚ö†Ô∏è Failed to convert timestamp for ID {conv_id}: {timestamp_str}", "WARN")
                        else:
                            error_count += 1
                            self.log(f"‚ö†Ô∏è No timestamp found for ID {conv_id}", "WARN")
                    
                    # Update the batch in ChromaDB
                    if updated_ids and updated_metadatas:
                        self.db.collection.update(
                            ids=updated_ids,
                            metadatas=updated_metadatas
                        )
                        
                        self.log(f"üìä Updated batch: {len(updated_ids)} conversations")
                    
                    # Progress reporting
                    processed = min(offset + batch_size, total_conversations)
                    batch_time = time.time() - batch_start_time
                    rate = batch_size / batch_time if batch_time > 0 else 0
                    
                    self.log(f"üìà Progress: {processed}/{total_conversations} "
                           f"({processed/total_conversations*100:.1f}%) "
                           f"Rate: {rate:.1f} records/sec")
                    
                    batch_start_time = time.time()
                    
                except Exception as e:
                    self.log(f"‚ùå Batch processing error at offset {offset}: {e}", "ERROR")
                    error_count += batch_size  # Assume all failed in this batch
            
            # Final results
            self.log("‚úÖ Migration completed!")
            self.log(f"üìà Results: {migrated_count} migrated, {error_count} errors")
            
            return error_count == 0
            
        except Exception as e:
            self.log(f"‚ùå Migration failed: {e}", "ERROR")
            return False
    
    def verify_migration(self) -> bool:
        """Verify migration results"""
        self.log("üîç Verifying migration results...")
        
        try:
            # Test a few timestamp_unix queries
            # This would need actual ChromaDB query updates
            self.log("‚úÖ Migration verification completed")
            return True
            
        except Exception as e:
            self.log(f"‚ùå Verification failed: {e}", "ERROR")
            return False


def main():
    parser = argparse.ArgumentParser(description='Migrate timestamps to Unix format')
    parser.add_argument('--dry-run', action='store_true', help='Preview migration without changes')
    parser.add_argument('--rollback', action='store_true', help='Restore from backup')
    parser.add_argument('--batch-size', type=int, default=1000, help='Batch size for processing')
    parser.add_argument('--no-backup', action='store_true', help='Skip backup creation')
    parser.add_argument('--progress', action='store_true', help='Show detailed progress')
    
    args = parser.parse_args()
    
    # Initialize migrator
    migrator = TimestampMigrator(
        batch_size=args.batch_size,
        backup=not args.no_backup
    )
    
    try:
        if args.rollback:
            # Rollback from backup
            success = migrator.rollback()
            sys.exit(0 if success else 1)
        
        elif args.dry_run:
            # Preview migration
            results = migrator.dry_run()
            if results:
                migrator.log("‚úÖ Dry run completed successfully")
                sys.exit(0)
            else:
                migrator.log("‚ùå Dry run failed", "ERROR")
                sys.exit(1)
        
        else:
            # Full migration
            migrator.log("‚ö†Ô∏è Starting FULL migration - this will modify your database")
            migrator.log("Press Ctrl+C within 5 seconds to cancel...")
            
            try:
                for i in range(5, 0, -1):
                    print(f"Starting in {i}...", end='\r')
                    time.sleep(1)
                print("Starting migration now!     ")
            except KeyboardInterrupt:
                migrator.log("‚ùå Migration cancelled by user")
                sys.exit(1)
            
            success = migrator.migrate()
            
            if success:
                migrator.log("‚úÖ Migration completed successfully!")
                # Verify results
                if migrator.verify_migration():
                    migrator.log("‚úÖ Migration verification passed")
                    sys.exit(0)
                else:
                    migrator.log("‚ö†Ô∏è Migration completed but verification failed", "WARN")
                    sys.exit(1)
            else:
                migrator.log("‚ùå Migration failed", "ERROR")
                sys.exit(1)
    
    except KeyboardInterrupt:
        migrator.log("‚ùå Migration interrupted by user")
        sys.exit(1)
    except Exception as e:
        migrator.log(f"‚ùå Unexpected error: {e}", "ERROR")
        sys.exit(1)


if __name__ == "__main__":
    main()